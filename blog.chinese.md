# LLM 记忆系统调研：2025 年技术全景与落地真相

Last Updated: 2025-12-28

> 大语言模型正在从"无状态对话"走向"有记忆的智能体"。这篇文章分享我对当前 LLM 记忆系统的调研发现，涵盖：**开源记忆框架**（Mem0/Letta/Graphiti）、**向量数据库**（Qdrant/Chroma）、**编程助手**（Cursor/Augment/Continue）、**ChatGPT 与 Claude 的记忆逆向工程**、**Agent CLI 工具分析**，以及**生产落地的真实现状**。

---

## 一、记忆框架：三种技术路线

当前主流的记忆框架呈现三种不同的技术哲学：

### Mem0：LLM 驱动的 CRUD

Mem0 的核心思路是用大模型来管理记忆的增删改查。它从对话中提取事实，遇到矛盾时让模型判断哪个版本更可信。

**落地验证**：Mem0 已成为 AWS Agent SDK 的官方记忆方案，有真实商业案例（Sunflower 医疗、RevisionDojo 教育）。这证明"简单但有效"在生产环境的价值。

### Letta：三层记忆 + 自主编辑

Letta（前身 MemGPT）设计了类似操作系统的三层架构：
- **Core Memory**：放在 system prompt 的核心事实
- **Recall Memory**：对话历史的向量检索
- **Archival Memory**：长期知识存储

独特之处在于让 Agent 自己决定何时更新记忆。已被 11x（销售 AI）、Kognitos（企业自动化）采用。

### Graphiti：双时态知识图谱

Graphiti 来自 Zep 团队，引入了时间维度——不仅记录"什么时候知道的"（transaction_time），还记录"事实本身发生在何时"（valid_time）。

这解决了状态变化问题：比如"用户去年住北京"和"用户现在住上海"都是真实的，传统系统难以同时保留。

---

## 二、向量数据库：两种定位

### Qdrant：性能与功能的平衡

Qdrant 追求的是"保持召回质量的同时支持复杂过滤"：可过滤的 HNSW 索引、稀疏向量支持、RRF/DBSF 混合排序。

生产中常见 Redis + Qdrant 双层架构：Redis 放热数据做快速访问，Qdrant 放冷数据做语义检索。

### Chroma：开发者体验优先

Chroma 选择了极致的开发者体验——pre-filtering 机制和简洁 API 让原型开发非常顺滑。目前正在进行 Rust v1.0 重写，开始补"性能"的课。

---

## 三、编程助手：记忆的实战应用

### Cursor：从用户行为中学习

Cursor 用 Agent 会话的 trace 数据来训练自己的 embedding 模型。它的向量表示是针对"代码理解"场景特化的，而非通用文本。

### Augment：实时增量索引

Augment 主打"实时"——监听编辑事件，动态更新个人代码索引。据公开数据，这带来了 2.6% 的质量提升。

### Continue：开放架构

Continue 选择了 BYOM（Bring Your Own Model）路线，配合内容寻址缓存。更像框架而非产品，适合定制化需求。

---

## 四、C 端产品逆向：ChatGPT vs Claude 记忆实现

通过逆向工程分析请求模式和系统行为，我发现 ChatGPT 和 Claude 采用了**截然不同的记忆架构**——这代表了两种根本性的设计哲学。

### ChatGPT：预计算注入（被动式记忆）

ChatGPT 的记忆是"始终注入"模式：

- **存储内容**：约 33 条事实摘要 + 近期对话摘要
- **注入时机**：每次对话开始时自动带上，用户无感知
- **更新机制**：后台异步提取，不影响对话延迟

**设计哲学**：牺牲 context 空间换取简单可靠。用户不需要等待检索，记忆"自然"地存在于对话中。

**权衡**：
- 优点：延迟低，体验流畅，实现简单
- 代价：固定占用 context 窗口，记忆容量受限

### Claude：按需检索（主动式记忆）

Claude 把记忆做成了**显式工具调用**：

- **工具接口**：`conversation_search`（语义搜索历史）、`recent_chats`（最近对话列表）
- **触发时机**：模型判断需要时才调用，用户可见"正在搜索记忆"
- **检索范围**：可跨越更长时间范围的对话历史

**设计哲学**：按需检索，精准匹配。只在真正需要时才消耗资源。

**权衡**：
- 优点：节省 token，理论上可支持更大规模记忆
- 代价：增加延迟，依赖模型正确判断何时需要记忆

### 两种模式的本质差异

| 维度 | ChatGPT（被动式） | Claude（主动式） |
|------|-------------------|------------------|
| 记忆触发 | 自动注入 | 工具调用 |
| 用户感知 | 无感知 | 可见"搜索中" |
| Context 占用 | 固定消耗 | 按需消耗 |
| 延迟 | 低 | 检索时增加 |
| 容量上限 | 受限于注入量 | 理论上更大 |
| 实现复杂度 | 低 | 高 |

这不仅是技术选择，更是**产品哲学**的体现：ChatGPT 追求"无感体验"，Claude 追求"透明可控"。

---

## 五、Agent CLI 工具：出乎意料的简单

研究 Claude Code、Codex、Gemini CLI 的实现后，我发现一个有趣的现象：**这些工具的"记忆"方案比想象中简单得多**。

| 工具 | 存储格式 | 压缩方式 |
|------|----------|----------|
| Claude Code | JSONL | 纯文本摘要 |
| Codex | JSONL | 加密 JWT 压缩 |
| Gemini | 服务端 | 每次压缩生成新会话文件 |

**关键发现**：没有复杂的 RAG 管道，没有知识图谱，就是朴素的滑动窗口 + 摘要压缩。这与学术论文中讨论的各种高级方案形成鲜明对比。

---

## 六、生产落地现状

### C 端产品：已上线记忆功能

ChatGPT 和 Claude 都已正式上线记忆功能，用户可以在日常对话中体验：

| 产品 | 记忆模式 | 核心特点 |
|------|----------|----------|
| ChatGPT | 被动注入 | 33 条事实摘要，无感体验 |
| Claude | 主动检索 | 工具调用，透明可控 |

这标志着：**记忆功能正在从实验特性变成产品标配**。

### B 端框架：垂直场景落地

| 框架 | 落地案例 | 特点 |
|------|----------|------|
| Mem0 | AWS Agent SDK、Sunflower、RevisionDojo | 简单方案最先落地 |
| Letta | 11x、Kognitos | 复杂有状态 Agent |
| Graphiti | Zep AI 平台核心 | 时态知识图谱 |

### 企业通用架构

大多数企业（沃尔玛、JP Morgan 等）不使用单一框架，而是构建**双层记忆架构**：

- **热层（Redis）**：最近 10-20 轮对话，快速访问
- **冷层（向量库）**：历史对话的语义检索

### 向量库的双重用途

一个容易混淆的点：向量数据库不仅用于 RAG（搜索文档回答问题），也用于**对话记忆**（搜索过去对话记住用户是谁）。Twilio、Aquant、OpenAI 都在用这种方式。

---

## 七、总结

### 技术层面

记忆系统正在从"向量检索"演进到"结构化 + 生命周期管理"。核心问题已经明确：**提取什么、如何存储、何时检索、怎样更新**。但最优解远未确定——事实提取、图结构、时态建模各有拥趸。

### 商业层面

记忆能力已成为核心差异化竞争点：

- **C 端产品**：ChatGPT 和 Claude 已将记忆做成标配功能
- **B 端框架**：Mem0 获 AWS 官方合作，证明记忆能力的商业价值
- **开发工具**：Cursor/Augment 用记忆提升代码理解，增强开发者留存

**现实是**：C 端已上线（ChatGPT/Claude），B 端仍在早期探索。真正的长期记忆、跨会话学习还有很长的路要走。

### 现状观察

最让我意外的发现是：**生产级 CLI 工具普遍采用简单方案**。这可能说明：

1. 简单方案在当前场景够用
2. 复杂方案的额外收益不足以覆盖其成本
3. 或者，更好的记忆系统是下一个竞争焦点

记忆是让 LLM 从"工具"变成"助手"的关键能力。目前技术栈仍在快速演进，值得持续关注。

---

## 相关资源

本文基于开源代码分析和产品逆向工程。完整调研材料：

- [Mem0 技术研究](mem0.research.md)
- [Letta 技术研究](letta.research.md)
- [Graphiti 技术研究](graphiti.research.md)
- [ChatGPT 记忆逆向工程](reverse-engineer/chatgpt-memory-reverse-engineering.md)
- [Claude 记忆逆向工程](reverse-engineer/claude-memory-reverse-engineering.md)
- [Agent CLI 会话文件分析](agent-cli/agent-files-analysis.md)
- [生产落地调研](production-adoption.research.md)

---

*研究时间：2025年12月*
