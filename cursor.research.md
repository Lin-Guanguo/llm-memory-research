# Cursor AI Technical Research Report

Last Updated: 2025-12-18

> **Research Methodology**: This document was generated by Claude Code using the chrome-devtools MCP server to explore and extract information from the Cursor documentation website and blog posts.

## Overview

Cursor is an AI-powered code editor that emphasizes **context management** as its core technical differentiator. Unlike simple chat interfaces, Cursor maintains multiple layers of context - from persistent Rules to indexed codebase embeddings - enabling AI to understand and work with large codebases effectively.

**Sources:**
- [Cursor Documentation](https://cursor.com/docs)
- [Cursor Blog](https://cursor.com/blog)

---

## 1. Core Insight: LLMs Have No Memory

> "Large language models don't retain memory between completions. Rules provide persistent, reusable context at the prompt level."
>
> — [Rules Documentation](https://cursor.com/docs/context/rules)

This fundamental limitation drives Cursor's entire architecture. Every feature - Rules, Indexing, Summarization - exists to solve the "memory problem" in different ways.

---

## 2. Context Architecture Overview

Cursor's context system operates at multiple levels:

```
┌─────────────────────────────────────────────────────────────┐
│                    Context Window                            │
├─────────────────────────────────────────────────────────────┤
│  1. System Prompt (Rules)                                    │
│     ├── Team Rules (highest precedence)                      │
│     ├── Project Rules (.cursor/rules/)                       │
│     └── User Rules (global preferences)                      │
├─────────────────────────────────────────────────────────────┤
│  2. Conversation History                                     │
│     ├── User messages                                        │
│     ├── AI responses                                         │
│     └── Tool call results                                    │
├─────────────────────────────────────────────────────────────┤
│  3. Attached Context                                         │
│     ├── @Files & Folders (explicit)                          │
│     ├── @Code (specific snippets)                            │
│     ├── @Docs (documentation)                                │
│     └── Auto-included (open files, terminal, linter)         │
└─────────────────────────────────────────────────────────────┘
```

Source: [@ Mentions Documentation](https://cursor.com/docs/context/mentions)

---

## 3. Codebase Indexing (Semantic Search)

### 7-Step Indexing Pipeline

Cursor transforms code into searchable vectors through this process:

| Step | Description |
|------|-------------|
| 1. File Sync | Workspace files securely synchronized with Cursor servers |
| 2. Chunking | Files broken into meaningful chunks (functions, classes, logical blocks) |
| 3. AI Embeddings | Each chunk converted to vector representation |
| 4. Vector Database | Embeddings stored in specialized database for fast similarity search |
| 5. Query Embedding | Search query converted to vector using same AI models |
| 6. Similarity Search | Find most similar code chunks by vector comparison |
| 7. Results | Relevant snippets ranked by semantic similarity |

Source: [Codebase Indexing Documentation](https://cursor.com/docs/context/codebase-indexing)

### Technical Specifications

| Metric | Value |
|--------|-------|
| **Sync Frequency** | Every 5 minutes (automatic) |
| **Search Availability** | At 80% indexing completion |
| **Update Strategy** | Incremental (only changed files reprocessed) |

### Custom Embedding Models

Cursor trains their own embedding models specifically for code retrieval:

> "Our approach uses agent sessions as training data: when an agent works through a task, it performs multiple searches and opens files before finding the right code. By analyzing these traces, we can see in retrospect what should have been retrieved earlier in the conversation."
>
> — [Improving agent with semantic search](https://cursor.com/blog/semsearch)

**Training Approach:**
1. Collect agent session traces (searches performed, files opened)
2. LLM ranks what content would have been most helpful at each step
3. Embedding model trained to align similarity scores with LLM-generated rankings
4. Creates feedback loop where model learns from actual coding tasks

### Semantic Search Impact (Research Results)

| Metric | Improvement |
|--------|-------------|
| **Accuracy** | 12.5% higher on average (6.5%-23.5% depending on model) |
| **Code Retention** | +0.3% overall, +2.6% on large codebases (1000+ files) |
| **User Satisfaction** | 2.2% fewer dissatisfied follow-up requests |

Source: [Improving agent with semantic search](https://cursor.com/blog/semsearch) (Nov 2025)

### Semantic Search vs Grep

> "Agent uses **both** grep and semantic search together. Grep excels at finding exact patterns, while semantic search excels at finding conceptually similar code. This combination delivers the best results."
>
> — [Codebase Indexing Documentation](https://cursor.com/docs/context/codebase-indexing)

| Feature | Semantic Search | Grep |
|---------|-----------------|------|
| **Timing** | Pre-computed (indexing) | Runtime search |
| **Matching** | Conceptual similarity | Exact patterns |
| **Example** | "top navigation" finds `header.tsx` | Only finds exact text |
| **Cost** | Cheaper at query time | More expensive |

### Team Index Features

| Feature | Description |
|---------|-------------|
| **Team Sharing** | Indexes shared across team members for faster indexing |
| **Smart Index Copying** | Accelerate indexing by copying from similar codebases |
| **Permission Respect** | Only shares accessible content |

Source: [Codebase Indexing FAQ](https://cursor.com/docs/context/codebase-indexing#faq)

---

## 4. Rules System (Persistent Context)

Rules provide **persistent, reusable context** at the prompt level - effectively a form of "memory" that persists across sessions.

### Rule Types & Precedence

```
Team Rules → Project Rules → User Rules
(highest)                    (lowest)
```

| Rule Type | Location | Scope | Applied When |
|-----------|----------|-------|--------------|
| **Team Rules** | Dashboard | Organization-wide | Always (if enforced) |
| **Project Rules** | `.cursor/rules/` | Per-project | Always / Intelligent / Pattern / Manual |
| **User Rules** | Cursor Settings | All projects | Always for Agent |
| **AGENTS.md** | Project root | Per-project | Always |

Source: [Rules Documentation](https://cursor.com/docs/context/rules)

### Project Rules Application Modes

| Mode | Behavior |
|------|----------|
| **Always Apply** | Included in every chat session |
| **Apply Intelligently** | Agent decides based on `description` field |
| **Apply to Specific Files** | When file matches `globs` pattern |
| **Apply Manually** | Only when `@rule-name` mentioned in chat |

### Rule File Format

```yaml
---
description: "Rule description for intelligent application"
globs: ["**/*.ts", "**/*.tsx"]
alwaysApply: false
---

Rule content in markdown...
```

---

## 5. Context Summarization

### Message Summarization

When conversations exceed context window limits, Cursor automatically summarizes older messages.

```
Before Summarization:
┌─────────────────────────────┐
│ User → Cursor → User → ... │ ← Exceeds limit
└─────────────────────────────┘

After Summarization:
┌─────────────────────────────┐
│ [Summarized Messages]       │
│ Recent Cursor response      │
│ Recent User message         │
│ Current Cursor response     │ ← Fits within limit
└─────────────────────────────┘
```

**Manual Trigger**: `/summarize` command compresses context on demand.

Source: [Summarization Documentation](https://cursor.com/docs/agent/chat/summarization)

### File & Folder Condensation

Large files undergo **smart condensation** to fit within context:

| State | Description |
|-------|-------------|
| **Full** | Entire file contents included |
| **Condensed** | Shows key structural elements (function signatures, classes, methods) |
| **Significantly Condensed** | Only file name shown to model |
| **Not Included** | Too large even in condensed form (warning icon shown) |

**Condensation Strategy:**
- Preserve structural elements (signatures, class definitions)
- Model can request expansion of specific sections if needed
- Maximizes effective use of available context window

Source: [File & Folder Condensation](https://cursor.com/docs/agent/chat/summarization#file--folder-condensation)

---

## 6. @ Mentions (Context Injection)

Users can explicitly inject context into conversations:

| Mention Type | Function |
|--------------|----------|
| `@Files` | Reference entire files |
| `@Folders` | Reference folder structure and contents |
| `@Code` | Reference specific code snippets (more granular than files) |
| `@Docs` | Include documentation (built-in or custom URLs) |

### @Docs System

- **Built-in docs**: Popular frameworks pre-indexed
- **Custom docs**: Add any URL, Cursor crawls and indexes all subpages
- **Team sharing**: Enable "Share with team" for organization-wide access

**Management**: `Cursor Settings > Indexing & Docs`

### Cursor 2.0 Changes

> "We've removed explicit items in the context menu, including `@Definitions`, `@Web`, `@Link`, `@Recent Changes`, `@Linter Errors`, and others. Agent can now self-gather context without needing to manually attach it in the prompt input."
>
> — [@ Mentions Changelog](https://cursor.com/docs/context/mentions#changelog)

Source: [@ Mentions Documentation](https://cursor.com/docs/context/mentions)

---

## 7. Privacy & Security

### Data Protection

> "Your code's privacy is protected through multiple layers of security. File paths are encrypted before being sent to our servers. Your actual code content is never stored in plaintext on our servers. Code is only held in memory during the indexing process, then discarded."
>
> — [Codebase Indexing Documentation](https://cursor.com/docs/context/codebase-indexing#privacy-and-security)

| Protection | Description |
|------------|-------------|
| **Path Encryption** | File paths encrypted before transmission |
| **No Plaintext Storage** | Code never stored in plaintext on servers |
| **Memory-Only Processing** | Code held in memory during indexing only |
| **No Permanent Storage** | Source code discarded after processing |

---

## 8. Memory Hierarchy Summary

```
┌─────────────────────────────────────────┐
│ Long-term: Codebase Index (Vector DB)   │  ← Persistent, searchable
├─────────────────────────────────────────┤
│ Persistent: Rules (Team/Project/User)   │  ← Cross-session context
├─────────────────────────────────────────┤
│ Session: Conversation + Summarization   │  ← Within-session context
├─────────────────────────────────────────┤
│ Transient: @ Mentions + Auto Context    │  ← Per-request context
└─────────────────────────────────────────┘
```

---

## 9. Key Takeaways

1. **No Native LLM Memory**: Cursor's architecture exists to compensate for LLMs' lack of persistent memory between completions

2. **Multi-Layer Context**: Four distinct layers from persistent (Rules, Index) to transient (@ Mentions)

3. **Custom Embedding Models**: Trained from agent session traces, learning what content is actually helpful during coding tasks

4. **Semantic + Grep Combined**: Both search methods used together for optimal results

5. **Smart Condensation**: Structural elements preserved when files too large for full inclusion

6. **Automatic Summarization**: Older messages compressed to maintain context window efficiency

7. **Team Context Sharing**: Rules and indexes can be shared across team members

8. **Privacy by Design**: Encryption, memory-only processing, no permanent code storage

---

## References

### Documentation
- [Codebase Indexing](https://cursor.com/docs/context/codebase-indexing)
- [Rules](https://cursor.com/docs/context/rules)
- [@ Mentions](https://cursor.com/docs/context/mentions)
- [Summarization](https://cursor.com/docs/agent/chat/summarization)

### Blog Posts (Technical)
- [Improving agent with semantic search](https://cursor.com/blog/semsearch) - November 2025
